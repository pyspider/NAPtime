#!/usr/bin/perl

use warnings;
use strict;
use Getopt::Long;
use File::Basename;
use File::Path qw(make_path remove_tree);
use List::Util qw(sum all any min max); 
use List::MoreUtils qw(pairwise);
use Algorithm::Loops qw(NestedLoops);
use POSIX;
use LWP::Simple;
use Parallel::ForkManager;
use Sys::Hostname;
use Time::HiRes qw(time);

####Dev####
use Data::Dumper;
use Storable;
use File::Slurp qw(read_file write_file);

my $version = "0.5.1"; #17/08/17

my $help;
my $outpath;
my %parameters;
our $debug;
my $doblast;
my %blastparams =(
	blasthits => 25,
	assignsens => 0.4
);
my $maxmapseqs = 2000000;
my $mode;
our $threads = 1;
our $verbose;

my $script = basename($0,());

########################################################
# USAGE
#
my $usage =<<USAGE;

Description:

	This is $script version $version of the NGS Amplicon Pipeline. It carries out either barcode selection or clustering of one or several fastas. When selecting barcodes, there are three modes: viewing statistics for a single file, running one or several files in batch mode with a set of parameters, or iterating through range(s) of parameter(s) to explore parameter space. Clustering only has the latter two modes.
	
	For more details, see the google doc documentation.
	
USAGE
#
######################################################

GetOptions("output=s"		=> \$outpath,
	   "mode=s"		=> \$mode,
	   "length_var=s"	=> \$parameters{length_var},
	   "cluster_method=s"	=> \$parameters{cluster_method},
	   "filter_chimeras=s"	=> \$parameters{filter_chimeras},
	   "cpv=s"		=> \$parameters{cpv},
	   "minsize=s"		=> \$parameters{minsize},
	   "seqlength=i"	=> \$parameters{seqlength},
	   "blastpath=s"	=> \$blastparams{blastpath},
	   "blasthits=s"	=> \$blastparams{blasthits},
	   "assignsens=s"	=> \$blastparams{assignsens},
	   "maxmapseqs=i"	=> \$maxmapseqs,
	   "doblast"		=> \$doblast,
	   "threads=i"		=> \$threads,
	   "verbose"		=> \$verbose,
	   "debug"		=> \$debug,
	   "help"		=> \$help) or die "Error: Incorrect options, try \"$script --help\" for more information.\n";

#
# Check and do parsing of inputs
#
print "$usage\n" and exit if($help);

die "I need some files to work on, see \"$script --help\" for more information\n" if(scalar @ARGV == 0);
die "Error: sequence length must be specified\n" unless(defined $parameters{seqlength});

if(!defined $outpath){
	die "Error: output directory must be specified, see \"$script --help\" for more information\n";
} else {
	print "Creating output directory if needed\n" if $verbose;
	make_path($outpath);
	make_path("$outpath/temp/");
	$outpath =~ s/\/$//;
}
my $pathroot = "$outpath/temp/cluster.";

$verbose = 1 if $debug;

my @files=@ARGV;


#
# Check for blast database and arrange threads
#

if(!$blastparams{blastpath} and $doblast){
	my $host = hostname;
	my %paths = (
		'ctag' => '/dh/blastdb/nt',
		'hpc-watson' => '/db/blastdb/nt'
	);
	if(exists($paths{$host})){
		$blastparams{blastpath} = $paths{$host};
	} else {
		die "Error: no path to BLAST database found, please give me one using --blastpath <path>\n";
	}
};
$blastparams{blastthreads} = $threads;


# Set defaults
$mode = "batch" unless(defined $mode);
my %paramdefaults = (
	'filter_chimeras'	=> 'no',
	'minsize'		=> 2,
	'cluster_method'	=> 'usearch',
	'cpv'			=> 3,
	'assigned_cpv'		=> 3,
	'length_var'		=> 1,
);
my @params = keys %parameters;
@parameters{@params} = map { defined $parameters{$_} ? $parameters{$_} : $paramdefaults{$_} } (@params);

if($parameters{filter_chimeras} eq 'both'){
	$parameters{filter_chimeras} = "yes,no";
	warn "\nWarning: cluster_method \"swarm\" does no chimera filtering\n" if $parameters{cluster_method} =~ /swarm/;
}elsif($parameters{filter_chimeras} eq 'no'){
	warn "\nWarning: cluster' method \"swarm\" does no chimera filtering, it is advisable to use a different option\n\n" if $parameters{cluster_method} =~ /swarm/;
}elsif($parameters{filter_chimeras} ne 'swarm' and $parameters{filter_chimeras} ne 'yes'){
	die "Error: value $parameters{filter_chimeras} passed to --filter_chimeras not recognised\n";
}

$parameters{seqconv} = $parameters{seqlength}/100;

#
# Set up parameter iterations
#
my ($iterations,$expand_parameters,$n_discarded) = parse_parameters($mode,\%parameters);
my @n_iter = sort keys %$iterations;

print "Debug: parsed iteration hash follows:" if $debug;
print Dumper \$iterations if $debug;

printf "%d iterations successfully parsed%s\n\n",$#n_iter+1,$n_discarded ? ", after $n_discarded removed for non-integer otu assignment parameter for swarm" : "" if($verbose and $#n_iter>0);

my %otusets;
my %stats = (
	general	=> ['input_sequences','iteration'],
	derep	=> ['sequence_length','sequence_length_variation_pc','minlength','maxlength','length_discarded','sequences_remain','n_groups','mean_groupsize','min_groupsize','max_groupsize'],
	size	=> ['n_groups_discarded_<minsize','n_groups_remain'],
	cluster	=> ['n_otus','n_chimeras_uchime','n_chimeras_cluster']
);

#
# Read in files then output raw
#
print "Reading and concatenating all files\n" if $verbose;
my %allfasta;
my %samples;
foreach my $file (@files){
	my %fasta = read_fasta($file,"check");
	printf "$file has %d sequences\n", scalar keys %fasta if $debug;
	warn "Warning: file $file is empty!\n" if(scalar keys %fasta < 1);
	my ($name,$dir)=fileparse($file);
	$name =~ s/^(.+)\.[^.]+$/$1/;
	$samples{$name}=0;
	@allfasta{keys %fasta} = values %fasta;
}

printf "Concatenation of %d files has %d sequences\n\n", scalar @files, scalar keys %allfasta;
#	die "Error, no sequences in any input fasta" if(scalar keys %allfasta<1);

my $allreads_raw = $pathroot."allreads_raw.fa";
open my $allraw, '>', $allreads_raw;
foreach my $id (keys %allfasta){
	print $allraw ">$id\n$allfasta{$id}\n";
}
close $allraw;

#
# Prep for pipeline
#
my $input_sequences = scalar keys %allfasta;
my $errormessage = "You may want to try running with fewer threads, and check that this directory has plenty of space available";


#
# Do dereplication
#

my %derep_log;
my %sort_log;

my $bpm = Parallel::ForkManager->new($threads);
my $bpm_done=0;

$bpm->run_on_finish( sub {
	my ($pid, $exit_code, $ident, $exit_signal, $core_dump, $data_structure_reference) = @_;
	$bpm_done++;
	printf "Completed $bpm_done/%d dereplication and size sorting iterations\n",(scalar @{${$expand_parameters}{length_var}} * scalar @{${$expand_parameters}{minsize}}) if $verbose and $mode eq 'eval';
	die "Error: size thread failed to output\n" unless $data_structure_reference;
	my $lvar = $data_structure_reference->{lvar};
	my $mins = $data_structure_reference->{mins};
	$sort_log{$lvar}{$mins} = $data_structure_reference->{slog};
	$derep_log{$lvar}{$mins} = $data_structure_reference->{dlog};
});

print "Starting dereplication and size sorting\n" if $verbose and $mode eq "batch";
printf "Starting %d dereplication and size sorting iterations using $threads threads \n", (scalar @{${$expand_parameters}{length_var}} * scalar @{${$expand_parameters}{minsize}}) if $verbose and $mode eq "eval";

foreach my $lvar (@{${$expand_parameters}{length_var}}){
	foreach my $mins (@{${$expand_parameters}{minsize}}){
		my $pid = $bpm->start and next;
	
		my ($dlog,$slog) = derep_sort_write(\%allfasta,$pathroot,$parameters{seqlength},$lvar,$mins,\%stats);
	
		$bpm->finish(0, {slog => $slog, dlog => $dlog, lvar => $lvar, mins => $mins});
	}
}

$bpm->wait_all_children;
print "\n";

# Can clear allfasta from memory now
undef %allfasta;



#
# Do clustering and mapping pipeline
#
my %cluster_log;

my $pm = Parallel::ForkManager->new($threads);
my $done_iterations=0;

$pm->run_on_finish( sub {
	my ($pid, $exit_code, $ident, $exit_signal, $core_dump, $data_structure_reference) = @_;
	$done_iterations++;
	printf "Completed $done_iterations/%d total iterations\r",($#n_iter+1) if $verbose and $mode eq 'eval';
	die "Error: iteration failed to output\n" unless $data_structure_reference;
	my $iter = $data_structure_reference->{iter};
	$cluster_log{$iter} = $data_structure_reference->{log};
	$otusets{$iter} = $data_structure_reference->{otus};
});

print "Starting clustering\n" if $verbose and $mode eq "batch";
printf "Starting %d clustering iterations using $threads threads \n", ($#n_iter+1) if $verbose and $mode eq "eval";

foreach my $iter (keys %$iterations){;
	my $pid = $pm->start and next;
	
	my ($log,$otus) = cluster_and_map($allreads_raw,$pathroot,$iterations,$iter,\@params,\%stats,$maxmapseqs,\%samples);
	
	$pm->finish(0, {log => $log, otus => $otus, iter => $iter});
}

$pm->wait_all_children;
print "\n";



#
# Process otus
#
if($doblast){
	print "BLASTing OTUs across all iterations and making best-guess taxonomies\n";

	my %allotuseqs;
	foreach my $iter (keys %otusets){
		foreach my $seq (keys %{$otusets{$iter}}){
			push(@{$allotuseqs{$seq}},"$iter,$otusets{$iter}{$seq}");
		}
	}

	my %seqstoblast;
	@seqstoblast{1..scalar keys %allotuseqs} = keys %allotuseqs;

	my $taxonomies = batch_taxonomyblast(\%seqstoblast,\%blastparams);
#	print Dumper $taxonomies;
	my $taxonomypath = "$outpath/cluster.otus.taxonomy.csv";
	open my $taxout, '>', $taxonomypath;
	print $taxout "iteration,otu_id,duplicate,taxonomy_lineage,nhits,n_contributing_lineages,prop_contributing_lineages,top_contributor_id,mean_contributor_id,mean_contributor_score\n";
	foreach my $id (keys %seqstoblast){
		my @duplicates = @{$allotuseqs{$seqstoblast{$id}}};
		foreach my $i (0..$#duplicates){
			print $taxout "$duplicates[$i],$i,",join(";",@{${$taxonomies}{$id}{bgt}}),",${$taxonomies}{$id}{nhits},${$taxonomies}{$id}{nmatch},${$taxonomies}{$id}{prop},";
			print $taxout "${$taxonomies}{$id}{topid},${$taxonomies}{$id}{id},${$taxonomies}{$id}{score}\n";
		}
	}
	close $taxout;
	print "Completed, taxonomies written to $taxonomypath\n";
}
#
# Output results log
#
my $logpath = "$outpath/cluster.$mode.log.csv";
open my $logcsv, '>',$logpath ;

my @head = (@{$stats{general}},@params,@{$stats{derep}},@{$stats{size}},@{$stats{cluster}});

print $logcsv join(',',@head);

foreach my $i (keys %$iterations){
	my $lvar = ${$iterations}{$i}{length_var};
	my $mins = ${$iterations}{$i}{minsize};
	print $logcsv "\n$input_sequences,$i,",
		join(',',@{$cluster_log{$i}}{@params},
			@{$derep_log{$lvar}{$mins}}{@{$stats{derep}}},
			@{$sort_log{$lvar}{$mins}}{@{$stats{size}}},
			@{$cluster_log{$i}}{@{$stats{cluster}}}
			);
}

close $logcsv;

print "\nCleaning temporary files\n" if $verbose and !$debug;
system "rm -rd $outpath/temp" unless $debug;

print "\nCSV log successfully written to $logpath\n" if $verbose;

exit;

sub cluster_and_map{
	my ($allreads_raw,$pathroot,$iterations,$iter,$params,$stats,$maxmapseqs,$samples) = @_;
	
	my %log;
	
	printf "%s: starting iteration $iter of %d with pid $$\n",timestamp(),scalar keys %$iterations if $verbose;
	my $printstring = join "", ($threads>1 and scalar keys %$iterations>1) ? " pid $$" : "" , scalar keys %$iterations>1 ? " iteration $iter" : "";
	
	#print Dumper ${$iterations}{$iter};
	
	#
	# Prepare paths
	#
		# Existing paths for source of this iteration
	my $sortpath = $pathroot."sort_lvar${$iterations}{$iter}{length_var}_mins${$iterations}{$iter}{minsize}.fa";
		# New paths
	$pathroot .= "iteration$iter.";
	my $chimerapath = $pathroot."chimeras.fa";
	my $nonchimerapath = $pathroot."nonchimeras.fa";
	my $otuspath = $pathroot."otus.fa";
	my $ucpath = $pathroot."map.uc";
	my $mappath = $pathroot."map.csv";
	my $swarmpath = $pathroot."swarmotus.csv";
	
	#
	# Perform clustering
	#
		
	my $n_chimeras_uchime = "NA";
	my $clusterinput = $sortpath;
	if(${$iterations}{$iter}{filter_chimeras} eq "yes" or ${$iterations}{$iter}{filter_chimeras} eq "swarm"){
		print timestamp(),":$printstring filtering chimeras\n" if $verbose;
		
		my $chimera_cmd = "usearch80 -uchime_denovo $sortpath -chimeras $chimerapath -nonchimeras $nonchimerapath 2>&1";
#		print "Command: $chimera_cmd\n";
		my $chimera_log = `$chimera_cmd`;
#		print $fh $chimera_log,"\n";

#		print "Log:\n$chimera_log\n";
		$chimera_log =~ /Writing\s(\d+)\schimeras/;
		$n_chimeras_uchime = $1;
#		print "uchime chimeras: $1\n";
		$clusterinput = $nonchimerapath;
		
		print timestamp(),":$printstring completed filtering $n_chimeras_uchime chimeras, written to $nonchimerapath\n" if $verbose;
	}
	
	my ($nOTUs,$n_chimeras_cluster);
	if (${$iterations}{$iter}{cpv} == 0){
		print timestamp(),":$printstring clustering skipped because assignment value is 0\n" if $verbose;
		system("cp $clusterinput $otuspath");
		my $seqs = `cat $clusterinput | grep -c '^>'`;
		($nOTUs,$n_chimeras_cluster) = ($seqs-{${$iterations}{$iter}{filter_chimeras} eq "yes"  ? 0 : $n_chimeras_uchime},"NA");
	} else {
		print timestamp(),":$printstring starting clustering using ${$iterations}{$iter}{cluster_method} assignment value ${$iterations}{$iter}{assigned_cpv} on file $clusterinput\n" if $verbose;
		if(${$iterations}{$iter}{cluster_method} eq "usearch"){
		
			my $cluster_cmd = "usearch80 -cluster_otus $clusterinput -otus $otuspath -otu_radius_pct ${$iterations}{$iter}{cpv} 2>&1";
	#		print "Command: $cluster_cmd\n";
			my $cluster_log = `$cluster_cmd`;
	#		print $fh $cluster_log,"\n";
	#		print "Log:\n$cluster_log\n";
			$cluster_log =~ /.*\s(\d+)\sOTUs,\s(\d+)\schimeras/s; #.* at beginning of regex ensures last OTU and chimera values selected (the function prints multiple lines of progress using \r!)
	#		print "cluster chimeras: $2\n";
			($nOTUs,$n_chimeras_cluster) = ($1,$2);
		} elsif(${$iterations}{$iter}{cluster_method} = "swarm"){
		
			my @bases = ('A','C','T','G');
			my $randbase = $bases[int(rand(4))];
			my $sed_cmd = "sed -i -e'/^>/ ! s/N/$randbase/g' $clusterinput";
	#		print $sed_cmd,"\n";
			system($sed_cmd);
			my $cluster_cmd = "swarm -z -t 1 -d ${$iterations}{$iter}{assigned_cpv} -o $swarmpath -w $otuspath $clusterinput 2>&1";
	#		print $cluster_cmd,"\n";
			my $cluster_log = `$cluster_cmd`;
	#		print $cluster_log,"\n";
			$cluster_log =~ /Number\sof\sswarms:\s+(\d+)/;
			($nOTUs,$n_chimeras_cluster) = ($1,"NA");
		}
	}
#	close $fh;
	print timestamp(),":$printstring completed clustering, $nOTUs OTUs written to $otuspath\n" if $verbose;
	
	#
	# Read OTUs to hash for output
	#
	
	my %otus = read_fasta($otuspath);
	my %otus_rev = map { $otus{$_} => $_ } keys %otus;
	
	#
	# Map OTUs
	#
	
	my $idpc;
	if(${$iterations}{$iter}{cpv} == 0){
		$idpc=0.99
	} else {
		$idpc=1-(${$iterations}{$iter}{cpv}/100);
	}
	print timestamp(),":$printstring starting mapping all reads to OTUs using id $idpc\n" if $verbose;
	my $mapcmd = "usearch80 -usearch_global $allreads_raw -db $otuspath -strand plus -id $idpc -uc $ucpath 2>&1";
	print "Command: $mapcmd\n";
	my $maplog=`$mapcmd`;
	print "Log:\n$maplog\n";
	if($maplog =~ /File\ssize\stoo\sbig/s){
		undef $maplog;
		unlink $ucpath;
		print timestamp(),":$printstring initial mapping failed, likely for too many sequences, attempting iterative mapping mode\n" if $verbose;
		my $ninseqs = `cat $allreads_raw | grep -c '^>'`;
		my $map_iterations = ceil($ninseqs/$maxmapseqs);
		
		#print timestamp(),":$printstring maplication loop $loop on file $allreads_raw with $ninseqs sequences, concatenating to $map_loop_out over $map_iterations iterations\n" if $verbose;
		foreach my $it (1..$map_iterations){
			my $linemin = 2*$maxmapseqs*($it-1)+1;
			my $linemax = 2*$maxmapseqs*$it;
			my $tempin = $pathroot."mapitersubin_$it.fa";
			my $tempout = $pathroot."mapitersubout_$it.uc";
			print timestamp(),":$printstring starting mapping iteration $it using lines $linemin to $linemax of $allreads_raw in temporary file $tempin\n" if $verbose;
			my $subcmd = "sed -n $linemin,$linemax"."p $allreads_raw > $tempin";
			system("$subcmd");
			my $map_cmd = "usearch80 -usearch_global $tempin -db $otuspath -strand plus -id $idpc -uc $tempout 2>&1";
			print "Command: $map_cmd\n" if $debug;
			my $maplog = `$map_cmd`;
			print "Log:\n$maplog\n" if $debug;
			printf "%s\n", (split("\n",$maplog))[7];
			system("cat $tempout >> $ucpath");
			system("rm $tempin $tempout") unless $debug;
			print timestamp(),":$printstring completed iteration $it, $tempout concatenated to $ucpath and temporary files deleted\n";
		}
		print timestamp(),":$printstring completed $map_iterations iterations, results concatenated to $ucpath\n" if $verbose;
	}
	
	convert_uc_and_write($ucpath,$mappath,$samples);
	
	print timestamp(),":$printstring completed mapping, map written to $mappath\n" if $verbose;
	
	#
	# Final logging and output
	#
	system("mv $otuspath $outpath/otus_iteration$iter.fa");
	system("mv $mappath $outpath/map_iteration$iter.csv");
	
	@log{@$params} = @{${$iterations}{$iter}}{@$params};
	@log{@{${$stats}{cluster}}} = ($nOTUs,$n_chimeras_uchime,$n_chimeras_cluster);
	
	print timestamp(),":$printstring completed\n" if $verbose;
	
	return (\%log,\%otus_rev);
}

sub derep_sort_write{
	my($allfasta,$pathroot,$len,$lvar,$mins,$stats) = @_;
	my $minl = floor($len-($lvar*$len)/100);
	my $maxl = ceil($len+($lvar*$len)/100);
	print timestamp(),": starting dereplication and sort iteration with length_var $minl%: $minl-${maxl}bp inclusive, and min group size $mins, pid $$\n" if $verbose;
	my %dlog;
	my %slog;
	
	my $printstring = join "", $threads>1 ? " pid $$" : "" , " length_var $lvar minsize $mins";
	
	my $sortpath = $pathroot."sort_lvar$lvar\_mins$mins.fa";
	
	#
	# Dereplicate all sequences within length variation
	#
	my $length_discarded = 0;
	my $length_passed = 0;
	my %dereplicated;
	foreach my $id (keys %$allfasta){
		if(length(${$allfasta}{$id})>=$minl and length(${$allfasta}{$id})<=$maxl){
			$dereplicated{${$allfasta}{$id}}++;
			$length_passed++;
		} else {
			$length_discarded++;
		}
	}
	
	#
	# Calculate statistics
	#
	my @groupsizes = values %dereplicated;
	my %sizecount;
	foreach my $size (@groupsizes){
		$sizecount{$size}++;
	}
	my $ngroup = scalar keys %dereplicated;
	my $singletons  = $sizecount{1} ? $sizecount{1} : 0;
	my $minsize = min(@groupsizes);
	my $topsize = max(@groupsizes);
	my $mean_groupsize = $length_passed/$ngroup;
	
	@dlog{@{${$stats}{derep}}} = ($len,$lvar,$minl,$maxl,$length_discarded,$length_passed,$ngroup,$mean_groupsize,$minsize,$topsize);
	
	print timestamp(),":$printstring discarded $length_discarded sequences <${minl}bp or >${maxl}bp, $length_passed sequences dereplicated into $ngroup unique sequences\n" if $verbose;
	
	#
	# Output sequences size sorted
	#
	my @sorted_seqs = sort { $dereplicated{$b} <=> $dereplicated{$a} } keys %dereplicated;
	open my $sorted, '>', $sortpath;
	my $bigenough = 0;
	foreach my $seq (@sorted_seqs){
		if($dereplicated{$seq}>=$mins){
			$bigenough++;
			print $sorted ">sequence$bigenough;size=$dereplicated{$seq};\n$seq\n";
		} else {
			last;
		}
	}
	
	my $n_groups_remain = $bigenough;
	my $minsize_discarded = $ngroup - $n_groups_remain;
	
	print timestamp(),":$printstring discarded $minsize_discarded groups, $n_groups_remain remain, written to $sortpath\n" if $verbose;
	
	@slog{@{${$stats}{size}}} = ($minsize_discarded,$n_groups_remain);
	
	return(\%dlog,\%slog);
}

sub batch_taxonomyblast{
	my ($queryhash,$parameters) = @_;
	my $querypath = "tempblastfasta.fa";
	my @ids = keys %$queryhash;
	my %out;
	my $maxcalls = 200;
	# output fasta
	open my $ofa, '>', $querypath;
	foreach my $id (keys %$queryhash){
		print $ofa ">$id\n${$queryhash}{$id}\n";
	}
	close $ofa;
	
	# blast
	printf "%d sequences to BLAST, this %s\n",scalar @ids, scalar @ids/${$parameters}{blastthreads}>6 ? scalar @ids/${$parameters}{blastthreads}>12 ? "will take some time" : "may take some time" : "won't take too long";
	my $blastcmd = "blastn -query $querypath -db ${$parameters}{blastpath} -num_threads ${$parameters}{blastthreads} -max_target_seqs ${$parameters}{blasthits} -outfmt \"6 qseqid sacc bitscore pident\"";
	my $blastdump;
	my $blasttries = 0;
	while(!$blastdump && $blasttries<5){
		$blasttries++;
		$blastdump = qx(bash -c '$blastcmd');
	}
#	open my $bd, '>', "blastdump.txt";
#	print $bd $blastdump;
#	close $bd;
	if($blastdump){
		print "Retrieving taxonomy information\n";
		my ($hits,$accessions) = parse_blastdump($blastdump);
		my $eutil_calls = ceil(scalar @$accessions/$maxcalls);
		printf "%d hits to retrieve data for, this will take at least %d seconds\n",scalar @$accessions, $eutil_calls;
		foreach my $call (1..$eutil_calls){
			my $starttime = time;
			my $min = ($call-1)*$maxcalls;
			my $max = $call*$maxcalls-1;
			$max = $max>$#{$accessions} ? $#{$accessions} : $max;
			print "eutil call $call for hits $min to $max...";
			my $accessionstring = join ",",@{$accessions}[$min..$max];
			my $nucdump = get("https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&id=$accessionstring&retmode=xml&rettype=fasta");
			my ($taxids,$taxidstring) = parse_nucdump($nucdump);
			my $taxdump = get("https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=taxonomy&id=$taxidstring");
			my $lineages = parse_taxdump($taxdump);
			$hits = merge_data($hits,$taxids,$lineages);
			my $duration = time - $starttime;
			print "took $duration seconds\n";
			sleep (0.7-$duration) if ($duration<0.7); #ensures the frequency of eutil requests is lower than 3 per second, as recommended by NCBI.
		}
		store $hits, "hithashstore.log" if $debug;
		print "Data retrieved, processing and making best guesses\n";
		foreach my $qid (@ids){
			if(!exists(${$hits}{$qid})){
				$out{$qid}{nhits} = 0;
				$out{$qid}{bgt} = ["NA"];
				$out{$qid}{nmatch} = 0;
				$out{$qid}{prop} = "NA";
				$out{$qid}{score} = "NA";
				$out{$qid}{id} = "NA";
				$out{$qid}{topid} = "NA";
				next;
			}
#			print "otu $qid ";
			my @linaoa;
			my @lin_acc;
			foreach my $acc (keys %{${$hits}{$qid}}){
				push @linaoa,[ split /;\s/,${$hits}{$qid}{$acc}{lineage} ];
				push @lin_acc, $acc;
				$out{$qid}{nhits}++;
			}
			
			my @matchi = ((1) x scalar @linaoa);
			my $totalhits = scalar @linaoa;
			my $maxlength = max( map { $#{$_} } @linaoa );
			my $outi = $maxlength;
			my $prop;
			my $nmatch;
			foreach my $ti (0..$maxlength){
				printf "run comparison for taxon $ti of %d lineages with maxlength of $maxlength taxa\n", scalar @linaoa if $debug;
				#print Dumper \@linaoa;
				my @testarray = map {$linaoa[$_][$ti]} (0..$#linaoa);
				{ no warnings 'uninitialized';print join(',',@testarray),"\n" if $debug;}
				@matchi = most_frequent_indices(@testarray);
				print join(',',@matchi),"\n";
				printf "comparison found %d identical...",sum(@matchi) if $debug;
				if(sum(@matchi)/$totalhits <= ${$parameters}{assignsens}){
					$outi = $ti-1;
					print "lineages too divergent, ending at taxon $outi\n" if $debug;
					last;
				}
				$nmatch = sum(@matchi);
				$prop = sum(@matchi)/$totalhits;
				print "sufficient similarity, subsetting..." if $debug;
				my @nextlinaoa;
				foreach my $i (0..$#linaoa){
					push @nextlinaoa,$linaoa[$i] if($linaoa[$i][$ti+1] and $matchi[$i]);
				}
				if(!@nextlinaoa){
					$outi = $ti;
					print "no further taxa for remaining lineages, ending at taxon $outi\n" if $debug;
					last;
				}
				$maxlength = max( map { $#{$_} } @nextlinaoa );
				printf "%d/$totalhits lineages remain for next comparison, new maxlength of $maxlength\n", scalar @nextlinaoa if $debug;
				@linaoa = @nextlinaoa;
			}
			
			my @ind = grep { $matchi[$_] == 1 } 0..$#matchi;
			my @acc_used = @lin_acc[@ind];
			$out{$qid}{bgt} = [ @{$linaoa[$ind[0]]}[0..$outi] ];
			$out{$qid}{nmatch} = $nmatch;
			$out{$qid}{prop} = $prop;
			my @scores = map {${$hits}{$qid}{$_}{score}} @acc_used;
			$out{$qid}{score} = sum(@scores)/scalar @scores;
			my @ids = map {${$hits}{$qid}{$_}{pident}} @acc_used;
			$out{$qid}{id} = sum(@ids)/scalar @ids;
			$out{$qid}{topid} = max(@ids);
		}
	}
	system("rm $querypath");
	print Dumper \%out if $debug;
	return \%out;
}

sub most_frequent_indices{
	my (@items) = @_;
	my %count;
	foreach my $item (@items){
		$count{$item}++ if($item);
	}
#	print Dumper \%count;
	my $max = max(values %count);
	my @mfis = map {!defined($_) ? 0 : $count{$_} == $max ? 1 : 0 } @items;
	return @mfis;
}

sub merge_data{
	my ($hits,$taxids,$lineages) = @_;
	foreach my $qid (keys %$hits){
		foreach my $acc (keys %{${$hits}{$qid}}){
			if(exists(${$taxids}{$acc})){
				my $tid = ${$taxids}{$acc};
				${$hits}{$qid}{$acc}{tid} = $tid;
				${$hits}{$qid}{$acc}{lineage} = ${$lineages}{$tid};
			}
		}
	}
	return $hits;
}

sub parse_blastdump{
	my ($blastdump) = @_;
	my %hits;
	open my $bd, '<', \$blastdump;
	my %acchash;
	while(my $row = <$bd>){
		chomp $row;
		my @line = split /\t/, $row;
		$hits{$line[0]}{$line[1]}{score} = $line[2];
		$hits{$line[0]}{$line[1]}{pident} = $line[3];
		$acchash{$line[1]} = 1;
	}
	close $bd;
	my @accessions = keys %acchash;
	return (\%hits,\@accessions);
}

sub parse_nucdump{
	my ($nucdump) = @_;
	my %tids;
	open my $nd, '<', \$nucdump;
	my @taxids;
	my ($acc,$tid);
	while(my $row = <$nd>){
		chomp $row;
#		print $row," - ";
		if($row eq "<TSeq>"){
			($acc,$tid) = (undef,undef);
#			print "start of section, reset\n";
		} elsif($row =~ /<TSeq_accver>([^.<]+)[^<]+<\/TSeq_accver>/){
			$acc = $1;
#			print "found accession $acc\n";
		} elsif($row =~ /<TSeq_taxid>(\d+)<\/TSeq_taxid>/){
			$tid = $1;
#			print "found tid $tid\n";
			push @taxids,$tid;
		} elsif($row eq "<\/TSeq>"){
			$tids{$acc} = $tid;
#			print "end of section, placed tid into hash\n"; 
#		} else {
#			print "not relevant\n";
		}
	}
	close $nd;
	my $taxidstring = join(',',@taxids);
	return (\%tids,$taxidstring);
}

sub parse_taxdump{
	my ($taxdump) = @_;
	my %lins;
	open my $td, '<', \$taxdump;
	my ($flag,$tid,$lineage, $species);
	while(my $row = <$td>){
		chomp $row;
#		print $row, " - ";
		if($row =~ /<Taxon>/){
			$flag++;
#			print "entering taxon of level $flag\n";
		} elsif($row =~ /<TaxId>(\d+)<\/TaxId>/ and $flag == 1){
			$tid = $1;
#			print "found taxid $tid\n"
		} elsif($row =~ /<Lineage>([^<]+)<\/Lineage>/ and $flag == 1){
			$lineage = $1;
#			print "found lineage $lineage\n";
		} elsif($row =~ /<ScientificName>([^<]+)<\/ScientificName>/ and $flag == 1){
			$species = $1;
#			print "found lineage $lineage\n";
		} elsif($row =~/<\/Taxon>/){
#			print "end of taxon level $flag";
			$flag--;
			if($flag == 0){
#				print "placing lineage into hash for tid and resetting\n";
				$lins{$tid} = $lineage;
				$lins{$tid} .= "; $species" if $species;
				($tid,$lineage,$species) = (undef,undef,undef);
#			} else {
#				print "not yet at low enough level to add to hash\n";
			}
#		} else {
#			print "not relevant\n";
		}
	}
	close $td;
	return \%lins;
}

sub timestamp{
my @time = localtime;
return sprintf "%02d:%02d:%02d",$time[2],$time[1],$time[0];
}

sub parse_parameters {
	my ($inmode, $inparams) = @_;
	my %param_expand;
	my @paramarray;
	my $n_singleparams;
	die "Input parameters not single values, did you mean to use \"--mode eval\"?\n" unless $inmode eq "eval" or all { $_ =~ /^[^,-]*$/ } values %$inparams;
	foreach my $param (keys %$inparams){
		push @paramarray,$param;
		if($inmode eq "batch"){
			$param_expand{$param} = [$inparams->{$param}];
		} elsif ($inmode eq "eval"){
			if ($inparams->{$param} =~ /^(\d+(\.\d+)?)-(\d+(\.\d+)?),(\d+(\.\d+)?)$/ ){
				my @values;
				my $curmax = $1;
				while ($curmax <= $3){
					push @values, $curmax;
					$curmax += $5;
				}
				$param_expand{$param} = \@values;
			} elsif($inparams->{$param} =~ /^[a-zA-Z]+(?:,[a-zA-Z]+)+$/){
				my @values = split ',',$inparams->{$param};
				$param_expand{$param} = \@values;
			} elsif($inparams->{$param} =~ /^[a-zA-Z]+$|^\d+(\.\d+)?$/){
				$param_expand{$param} = [$inparams->{$param}];
				$n_singleparams++;
				die "No parameter ranges given, did you mean to use \"--mode batch\"?\n" if($n_singleparams == scalar keys %$inparams);
			} else {
				die "Could not successfully parse string given for $param\n";
			}
		} else {
			die "Argument passed to --mode not recognised, see \"$script --help\" for more information\n"
		}
	}
	my @allarray;
	NestedLoops([@param_expand{@paramarray}], sub {push @allarray, [ @_ ]});
#	print Dumper \@allarray;
	my $nonint_removed;
	my %iterhash;
	my %checkswarmcpv
	foreach my $it (0 .. $#allarray){
		$iterhash{$it+1} = {map { $paramarray[$_] => $allarray[$it][$_] } 0..$#paramarray};
		if($iterhash{$it+1}{cluster_method} eq "swarm"){
			$iterhash{$it+1}{assigned_cpv} = printf("%.0f", $iterhash{$it+1}{cpv}*$parameters{seqconv});
			$iterhash{$it+1}{cpv} = $iterhash{$it+1}{assigned_cpv}/$parameters{seqconv};
			if(exists $checkswarmcpv{$iterhash{$it+1}{cpv}}){
				delete $iterhash{$it+1};
				$nonint_removed++;
			} else {
				$checkswarmcpv{$iterhash{$it+1}{cpv}} = 1;
			}
		} else {
			$iterhash{$it+1}{assigned_cpv} = $iterhash{$it+1}{cpv}
		}
	}
	my $newid = 1;
	my %newhash;
	foreach my $oldid (keys %iterhash){
		$newhash{$newid} = $iterhash{$oldid};
		$newid++
	}
	return (\%newhash,\%param_expand,$nonint_removed);
}

sub read_fasta {
	my ($fapathin,$checklabel) = @_;
	my %fasta;
	my $id;
	my ($name,$dir)=fileparse($fapathin);
	$name =~ s/^(.+)\.[^.]+$/$1/;
	my $barcodelabelsadded = 0;
	open my $fa_in, '<', $fapathin or die "Couldn't open $fapathin\n";
	while(my $row = <$fa_in>){
		chomp $row;
		if($row =~ /^>(.+)$/){
			$id = $1;
			if($checklabel and !($id =~ /;barcodelabel=[^;]+;/)){
				$barcodelabelsadded++;
				$id.=";barcodelabel=$name;";
			}
			$id =~ s/\s/_/g;
		} elsif($row =~ /^[ATCGNatcgn]+$/){
			$fasta{$id} .= $row;
		} else { die "Couldn't read fasta format in $fapathin" };
	}
	close $fa_in;
	print "File $fapathin missing barcode labels, \";barcodelabel=$name;\" appended to header of $barcodelabelsadded sequences\n" if $checklabel and $barcodelabelsadded and $verbose;
	return %fasta;
}

sub convert_uc_and_write {
	my ($ucpath,$outpath,$samples) = @_;
	my %tab;
	my %otus;
	open my $uc, '<', $ucpath or die "Error opening $ucpath\n";
	while(my $row = <$uc>){
		chomp $row;
		if($row =~ /^H.*barcodelabel=([^;]+);\t(.*)$/){
			$tab{$1}{$2}++;
			${$samples}{$1}++;
			$otus{$2}=1;
		}
	}
	close $uc;
	
	open my $csv, '>', $outpath or die "Error opening $outpath\n";
	print $csv "sample,",join(",",sort keys %otus),"\n";
	foreach my $sample (sort keys %$samples){
		print $csv $sample;
		if(${$samples}{$sample}>0){
			foreach my $otu (sort keys %otus){
				print $csv ",",$tab{$sample}{$otu} ? $tab{$sample}{$otu} : 0;
			}
		} else {
			print $csv ",0" x scalar keys %otus;
		}
		print $csv "\n";
	}
	close $csv;
}
