#!/usr/bin/perl

use warnings;
use strict;
use Getopt::Long;
use File::Basename;
use File::Path qw(make_path remove_tree);
use List::Util qw(sum all any min max); 
use List::MoreUtils qw(pairwise);
use Algorithm::Loops qw(NestedLoops);
use POSIX;
use LWP::Simple;
use Parallel::ForkManager;
use Sys::Hostname;
use Time::HiRes qw(time);

####Dev####
use Data::Dumper;
use Storable;
use File::Slurp qw(read_file write_file);

my $version = "0.3.2"; #22/5/17

my $help;
my $outpath;
my %parameters;
my $doblast;
my %blastparams =(
	blasthits => 25,
	assignsens => 0.4
);
my $mode;
our $threads = 1;
our $verbose;

my $script = basename($0,());

########################################################
# USAGE
#
my $usage =<<USAGE;

Description:

	This is $script version $version of the NGS Amplicon Pipeline. It carries out either barcode selection or clustering of one or several fastas. When selecting barcodes, there are three modes: viewing statistics for a single file, running one or several files in batch mode with a set of parameters, or iterating through range(s) of parameter(s) to explore parameter space. Clustering only has the latter two modes.
	
	For more details, see the google doc documentation.
	
USAGE
#
######################################################

GetOptions("output=s"		=> \$outpath,
	   "mode=s"		=> \$mode,
	   "minlength=s"	=> \$parameters{minlength},
	   "cluster_method=s"	=> \$parameters{cluster_method},
	   "filter_chimeras=s"	=> \$parameters{filter_chimeras},
	   "otuassign=s"	=> \$parameters{otuassign},
	   "minsize=s"		=> \$parameters{minsize},
	   "blastpath=s"	=> \$blastparams{blastpath},
	   "blasthits=s"	=> \$blastparams{blasthits},
	   "assignsens=s"	=> \$blastparams{assignsens},
	   "doblast"		=> \$doblast,
	   "threads=i"		=> \$threads,
	   "verbose"		=> \$verbose,
	   "help"		=> \$help) or die "Error: Incorrect options, try \"$script --help\" for more information.\n";

#
# Check and do parsing of inputs
#
print "$usage\n" and exit if($help);

die "I need some files to work on, see \"$script --help\" for more information\n" if(scalar @ARGV == 0);
die "Error: minlength must be specified\n" unless(defined $parameters{minlength});
if(!defined $outpath){
	die "Error: output directory must be specified, see \"$script --help\" for more information\n";
} else {
	print "Creating output directory if needed\n" if $verbose;
	make_path($outpath);
	make_path("$outpath/temp/");
	$outpath =~ s/\/$//;
}

my @files=@ARGV;

#
# Check for blast database and arrange threads
#

if(!$blastparams{blastpath} and $doblast){
	my $host = hostname;
	my %paths = (
		'ctag' => '/dh/blastdb/nt',
		'hpc-watson' => '/db/blastdb/nt'
	);
	if(exists($paths{$host})){
		$blastparams{blastpath} = $paths{$host};
	} else {
		die "Error: no path to BLAST database found, please give me one using --blastpath <path>\n";
	}
};
$blastparams{blastthreads} = $threads;


# Set defaults
$mode = "batch" unless(defined $mode);
my %paramdefaults = (
	'filter_chimeras'	=> 'no',
	'minsize'		=> 2,
	'cluster_method'	=> 'usearch',
	'otuassign'		=> 3,
);
my @params = keys %parameters;
@parameters{@params} = map { defined $parameters{$_} ? $parameters{$_} : $paramdefaults{$_} } (@params);

if($parameters{filter_chimeras} eq 'both'){
	$parameters{filter_chimeras} = "yes,no";
	warn "\nWarning: cluster_method \"swarm\" does no chimera filtering\n" if $parameters{cluster_method} =~ /swarm/;
}elsif($parameters{filter_chimeras} eq 'no'){
	warn "\nWarning: cluster method \"swarm\" does no chimera filtering, it is advisable to use a different option\n\n" if $parameters{cluster_method} =~ /swarm/;
}elsif($parameters{filter_chimeras} ne 'swarm' and $parameters{filter_chimeras} ne 'yes'){
	die "Error: value $parameters{filter_chimeras} passed to --filter_chimeras not recognised\n";
}

#
# Set up parameter iterations
#
my ($iterations,$n_discarded) = parse_parameters($mode,\%parameters);
my @n_iter = sort keys %$iterations;

printf "%d iterations successfully parsed%s\n\n",$#n_iter+1,$n_discarded ? ", after $n_discarded removed for non-integer otu assignment parameter for swarm" : "" if($verbose and $#n_iter>0);

my %log;
my %otusets;
my %stats = (
	general => ['filename','sequences','iteration','n_seq_discarded_<minlength','n_groups','n_groups_discarded_<minsize','n_groups_remain'],
	group   => ['mean_groupsize','min_groupsize','max_groupsize'],
	cluster => ['n_otus','n_chimeras_uchime','n_chimeras_cluster']
);

#
# Read in files
#
print "Reading and concatenating all files\n" if $verbose;
my %allfasta;
foreach my $file (@files){
	my %fasta = read_fasta($file,"check");
#	printf "$file has %d sequences\n", scalar keys %fasta;
	warn "Warning: file $file is empty!\n" if(scalar keys %fasta < 1);
	@allfasta{keys %fasta} = values %fasta;
}

	printf "Concatenation of %d files has %d sequences\n", scalar @files, scalar keys %allfasta;
#	die "Error, no sequences in any input fasta" if(scalar keys %allfasta<1);

#
# Do pipeline
#

my $pm = Parallel::ForkManager->new($threads);
my $done_iterations=0;

$pm->run_on_finish( sub {
	my ($pid, $exit_code, $ident, $exit_signal, $core_dump, $data_structure_reference) = @_;
	$done_iterations++;
	printf "Completed $done_iterations/%d total iterations\r",($#n_iter+1) if $verbose and $mode eq 'eval';
	my $iter = $data_structure_reference->{iter};
	$log{$iter} = $data_structure_reference->{log};
	$otusets{$iter} = $data_structure_reference->{otus};
});

print "Starting clustering\n" if $verbose and $mode eq "batch";
printf "Starting %d clustering iterations using $threads threads \n", ($#n_iter+1) if $verbose and $mode eq "eval";

foreach my $iter (keys %$iterations){;
	my $pid = $pm->start and next;
	
	my ($log,$otus) = group_sort_and_cluster(\%allfasta,$iterations,$iter,\@params,\%stats);
	
	$pm->finish(0, {log => $log, otus => $otus, iter => $iter});
}

$pm->wait_all_children;
print "\n";

#
# Process otus
#
if($doblast){
	print "BLASTing OTUs across all iterations and making best-guess taxonomies\n";

	my %allotuseqs;
	foreach my $iter (keys %otusets){
		foreach my $seq (keys %{$otusets{$iter}}){
			push(@{$allotuseqs{$seq}},"$iter,$otusets{$iter}{$seq}");
		}
	}

	my %seqstoblast;
	@seqstoblast{1..scalar keys %allotuseqs} = keys %allotuseqs;

	my $taxonomies = batch_taxonomyblast(\%seqstoblast,\%blastparams);
	print Dumper $taxonomies;
	my $taxonomypath = "$outpath/cluster.otus.taxonomy.txt";
	open my $taxout, '>', $taxonomypath;
	print $taxout "iteration,otu_id,duplicate,taxonomy_lineage,nhits\n";
	foreach my $id (keys %seqstoblast){
		my @duplicates = @{$allotuseqs{$seqstoblast{$id}}};
		foreach my $i (0..$#duplicates){
			print $taxout "$duplicates[$i],$i,",join(";",@{${$taxonomies}{$id}{bgt}}),",${$taxonomies}{$id}{nhits}\n";
		}
	}
	close $taxout;
	print "Completed, taxonomies written to $taxonomypath\n";
}
#
# Output results log
#
my $logpath = "$outpath/cluster.$mode.log.csv";
open my $logcsv, '>',$logpath ;

my @head = (@{$stats{general}},@params,@{$stats{group}},@{$stats{cluster}});

print $logcsv join(',',@head);

foreach my $i (keys %log){
	print $logcsv "\n",join(',',@{$log{$i}}{@head});
}

close $logcsv;

print "\nCleaning temporary files\n" if $verbose;
#system "rm -rd $outpath/temp";

print "\nCSV log successfully written to $logpath\n" if $verbose;

exit;

sub group_sort_and_cluster{
	my ($allfasta,$iterations,$iter,$params,$stats) = @_;
	
	my %log;
	
	printf "%s: starting iteration $iter of %d with pid $$\n",timestamp(),scalar keys %$iterations if $verbose;
	my $printstring = join "", ($threads>1 and scalar keys %$iterations>1) ? " pid $$" : "" , scalar keys %$iterations>1 ? " iteration $iter" : "";
	
	#print Dumper ${$iterations}{$iter};
	
	#
	# Prepare paths
	#
	my $pathroot = "$outpath/temp/cluster.iteration$iter\_";
	
	my $allreadspath = $pathroot."allreads.fa";
	my $dereppath = $pathroot."derep.fa";
	my $sortpath = $pathroot."sort.fa";
	my $chimerapath = $pathroot."chimeras.fa";
	my $nonchimerapath = $pathroot."nonchimeras.fa";
	my $otuspath = $pathroot."otus.fa";
	my $ucpath = $pathroot."map.uc";
	my $mappath = $pathroot."map.csv";
	
	my $errormessage = "You may want to try running with fewer threads, and check that this directory has plenty of space available";
	
	#
	# Write all sequences greater than minlength for later mapping
	#
	my $minlength_discarded;
	my $allreads_written;
	open my $allout, '>', $allreadspath or die "Error writing to $allreadspath\n";
	
	foreach my $id (keys %$allfasta){
		if(length(${$allfasta}{$id})>=${$iterations}{$iter}{minlength}){
			print $allout ">$id\n${$allfasta}{$id}\n";
			$allreads_written++;
		} else {
			$minlength_discarded++;
		}
	}
	close $allout;
	

	print timestamp(),":$printstring discarded $minlength_discarded sequences <${$iterations}{$iter}{minlength}bp, remaining $allreads_written written to $allreadspath\n" if $verbose;
	
	#
	# Group all sequences ##TODO: if there are greater than n sequences in the allreads file, do multiple dereplications then dereplicate the outputs.
	#
	print timestamp(),":$printstring starting dereplicating\n" if $verbose;
	
	my $derep_cmd = "usearch80 -derep_fulllength $allreadspath -fastaout $dereppath -sizeout 2>&1";
#	print "Command: $derep_cmd\n";
	my $derep_log = `$derep_cmd`;
	my ($inputseqs,$ngroup,$singletons,$minsize,$topsize,$mean_groupsize);
	if($derep_log =~ /^.+\s(\d+)\sseqs,\s(\d+)\suniques,\s(\d+)\ssingletons.+size\s(\d+).+max\s(\d+),\savg\s(\d+(?:\.\d+)).+$/s){
		($inputseqs,$ngroup,$singletons,$minsize,$topsize,$mean_groupsize) = ($1,$2,$3,$4,$5,$6);
	} elsif ($derep_log =~ /Memory limit of 32-bit process exceeded/) {
		die "ERROR: $printstring usearch80 -derep_fulllength exceeded memory limit and failed. $errormessage\n";
	} elsif ($derep_log =~ /Fatal error/){
		die "ERROR: $printstring usearch80 -derep_fulllength failed for an unknown reason, full log follows: $derep_log\n$errormessage\n";
	} else {
		warn "WARNING: $printstring usearch80 -derep_fulllength failed to parse output for some reason, and probably failed to run properly entirely\n";
	}
	
	print timestamp(),":$printstring completed dereplication, $ngroup groups written to $dereppath\n" if $verbose;
	
	#
	# Sort by size 
	#
	print timestamp(),":$printstring starting sorting and discarding groups <${$iterations}{$iter}{minsize} members\n" if $verbose;
	
	my $sort_cmd = "usearch80 -sortbysize $dereppath -fastaout $sortpath -minsize ${$iterations}{$iter}{minsize} 2>&1";
	my $sort_log = `$sort_cmd`;
	my $n_groups_remain;
	if($sort_log =~ /\s(\d+)\ssequences/){
		$n_groups_remain = $1;
	} elsif ($sort_log =~ /Fatal error/){
		die "ERROR: $printstring usearch80 -sortbysize failed with an error, full log follows: $sort_log\n$errormessage\n";
	} else {
		warn "WARNING: $printstring usearch80 -sortbysize failed to parse output for some reason, and probably failed to run properly entirely\n";
	}
	my $minsize_discarded = $ngroup-$n_groups_remain;
	
	print timestamp(),":$printstring discarded $minsize_discarded groups, $n_groups_remain remain, written to $sortpath\n" if $verbose;
	
	#
	# Do logging
	#
	@log{@{${$stats}{general}}} = ("Dereplicated concatenated samples", scalar keys %$allfasta, $iter, $minlength_discarded, $ngroup, $minsize_discarded, $n_groups_remain);
	@log{@{${$stats}{group}}} = ($mean_groupsize,$minsize,$topsize);
	@log{@$params} = @{${$iterations}{$iter}}{@$params};
	
	#
	# Perform clustering
	#
#	open my $fh, '>', "temp.txt";
		
	my $n_chimeras_uchime = "NA";
	my $clusterinput = $sortpath;
	if(${$iterations}{$iter}{filter_chimeras} eq "yes" or ${$iterations}{$iter}{filter_chimeras} eq "swarm"){
		print timestamp(),":$printstring filtering chimeras\n" if $verbose;
		
		my $chimera_cmd = "usearch80 -uchime_denovo $sortpath -chimeras $chimerapath -nonchimeras $nonchimerapath 2>&1";
#		print "Command: $chimera_cmd\n";
		my $chimera_log = `$chimera_cmd`;
#		print $fh $chimera_log,"\n";

#		print "Log:\n$chimera_log\n";
		$chimera_log =~ /Writing\s(\d+)\schimeras/;
		$n_chimeras_uchime = $1;
#		print "uchime chimeras: $1\n";
		$clusterinput = $nonchimerapath;
		
		print timestamp(),":$printstring completed filtering $n_chimeras_uchime chimeras, written to $nonchimerapath\n" if $verbose;
	}
	
	my ($nOTUs,$n_chimeras_cluster);
	if (${$iterations}{$iter}{otuassign} == 0){
		print timestamp(),":$printstring clustering skipped because assignment value is 0\n" if $verbose;
		system("cp $clusterinput $otuspath");
		($nOTUs,$n_chimeras_cluster) = ($n_groups_remain-{${$iterations}{$iter}{filter_chimeras} eq "yes"  ? 0 : $n_chimeras_uchime},"NA");
	} else {
		print timestamp(),":$printstring starting clustering using ${$iterations}{$iter}{cluster_method} assignment value ${$iterations}{$iter}{otuassign} on file $clusterinput\n" if $verbose;
		if(${$iterations}{$iter}{cluster_method} eq "usearch"){
		
			my $cluster_cmd = "usearch80 -cluster_otus $clusterinput -otus $otuspath -otu_radius_pct ${$iterations}{$iter}{otuassign} 2>&1";
	#		print "Command: $cluster_cmd\n";
			my $cluster_log = `$cluster_cmd`;
	#		print $fh $cluster_log,"\n";
	#		print "Log:\n$cluster_log\n";
			$cluster_log =~ /.*\s(\d+)\sOTUs,\s(\d+)\schimeras/s; #.* at beginning of regex ensures last OTU and chimera values selected (the function prints multiple lines of progress using \r!)
	#		print "cluster chimeras: $2\n";
			($nOTUs,$n_chimeras_cluster) = ($1,$2);
		} elsif(${$iterations}{$iter}{cluster_method} = "swarm"){
		
			my @bases = ('A','C','T','G');
			my $randbase = $bases[int(rand(4))];
			my $sed_cmd = "sed -i -e'/^>/ ! s/N/$randbase/g' $clusterinput";
	#		print $sed_cmd,"\n";
			system($sed_cmd);
			my $cluster_cmd = "swarm -z -t 1 -d ${$iterations}{$iter}{otuassign} -w $otuspath $clusterinput 2>&1";
			print $cluster_cmd,"\n";
			my $cluster_log = `$cluster_cmd`;
			print $cluster_log,"\n";
			$cluster_log =~ /Number\sof\sswarms:\s+(\d+)/;
			($nOTUs,$n_chimeras_cluster) = ($1,"NA");
		}
	}
#	close $fh;
	print timestamp(),":$printstring completed clustering, $nOTUs OTUs written to $otuspath\n" if $verbose;
	
	#
	# Read OTUs to hash for output
	#
	
	my %otus = read_fasta($otuspath);
	my %otus_rev = map { $otus{$_} => $_ } keys %otus;
	
	#
	# Map OTUs
	#
	
	my $idpc;
	if(${$iterations}{$iter}{otuassign} == 0){
		$idpc=0.99
	} elsif(${$iterations}{$iter}{cluster_method} eq "usearch"){
		$idpc=1-(${$iterations}{$iter}{otuassign}/100);
	} else {
		$idpc = 0.97;
	}
	print timestamp(),":$printstring starting mapping all reads to OTUs using id $idpc\n" if $verbose;
	my $mapcmd = "usearch80 -usearch_global $allreadspath -db $otuspath -strand plus -id $idpc -uc $ucpath 2>&1";
#	print "Command: $mapcmd\n";
	my $maplog=`$mapcmd`;
#	print "Log:\n$maplog\n";
	convert_uc_and_write($ucpath,$mappath);
	
	print timestamp(),":$printstring completed mapping, map written to $mappath\n" if $verbose;
	
	#
	# Final logging and output
	#
	system("mv $otuspath $outpath/otus_iteration$iter.fa");
	system("mv $mappath $outpath/map_iteration$iter.csv");
	
	@log{@{${$stats}{cluster}}} = ($nOTUs,$n_chimeras_uchime,$n_chimeras_cluster);
	print timestamp(),":$printstring completed\n" if $verbose;
	system("rm $allreadspath");
	return (\%log,\%otus_rev);
}

sub batch_taxonomyblast{
	my ($queryhash,$parameters) = @_;
	my $querypath = "tempblastfasta.fa";
	my @ids = keys %$queryhash;
	my %out;
	my $maxcalls = 200;
	# output fasta
	open my $ofa, '>', $querypath;
	foreach my $id (keys %$queryhash){
		print $ofa ">$id\n${$queryhash}{$id}\n";
	}
	close $ofa;
	
	# blast
	printf "%d sequences to BLAST, this %s\n",scalar @ids, scalar @ids/${$parameters}{blastthreads}>6 ? scalar @ids/${$parameters}{blastthreads}>12 ? "will take some time" : "may take some time" : "won't take too long";
	my $blastcmd = "blastn -query $querypath -db ${$parameters}{blastpath} -num_threads ${$parameters}{blastthreads} -max_target_seqs ${$parameters}{blasthits} -outfmt \"6 qseqid sacc bitscore\"";
	my $blastdump;
	my $blasttries = 0;
	while(!$blastdump && $blasttries<5){
		$blasttries++;
		$blastdump = qx(bash -c '$blastcmd');
	}
#	open my $bd, '>', "blastdump.txt";
#	print $bd $blastdump;
#	close $bd;
	if($blastdump){
		print "Retrieving taxonomy information\n";
		my ($hits,$accessions) = parse_blastdump($blastdump);
		my $eutil_calls = ceil(scalar @$accessions/$maxcalls);
		printf "%d hits to retrieve data for, this will take at least %d seconds\n",scalar @$accessions, $eutil_calls;
		foreach my $call (1..$eutil_calls){
			my $starttime = time;
			my $min = ($call-1)*$maxcalls;
			my $max = $call*$maxcalls-1;
			$max = $max>$#{$accessions} ? $#{$accessions} : $max;
			print "eutil call $call for hits $min to $max...";
			my $accessionstring = join ",",@{$accessions}[$min..$max];
			my $nucdump = get("https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&id=$accessionstring&retmode=xml&rettype=fasta");
			my ($taxids,$taxidstring) = parse_nucdump($nucdump);
			my $taxdump = get("https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=taxonomy&id=$taxidstring");
			my $lineages = parse_taxdump($taxdump);
			$hits = merge_data($hits,$taxids,$lineages);
			my $duration = time - $starttime;
			print "took $duration seconds\n";
			sleep (0.7-$duration) if ($duration<0.7); #ensures the frequency of eutil requests is lower than 3 per second, as recommended by NCBI.
		}
		store $hits, "hithashstore.log";
		print "Data retrieved, processing and making best guesses\n";
		foreach my $qid (@ids){
			if(!exists(${$hits}{$qid})){
				$out{$qid}{nhits} = 0;
				$out{$qid}{bgt} = ["NA"];
				next;
			}
#			print "otu $qid ";
			my @linaoa;
			foreach my $acc (keys %{${$hits}{$qid}}){
				push @linaoa,[ split /;\s/,${$hits}{$qid}{$acc}{lineage} ];
				$out{$qid}{nhits}++;
			}
			
			my @matchi = ((1) x scalar @linaoa);
			my $totalhits = scalar @linaoa;
			my $maxlength = max( map { $#{$_} } @linaoa );
			my $outi = $maxlength;
			foreach my $ti (0..$maxlength){
				printf "run comparison for taxon $ti of %d lineages with maxlength of $maxlength taxa\n", scalar @linaoa;
				#print Dumper \@linaoa;
				my @testarray = map {$linaoa[$_][$ti]} (0..$#linaoa);
				{ no warnings 'uninitialized';print join(',',@testarray),"\n";}
				@matchi = most_frequent_indices(@testarray);
				print join(',',@matchi),"\n";
				printf "comparison found %d identical...",sum(@matchi);
				if(sum(@matchi)/$totalhits <= ${$parameters}{assignsens}){
					$outi = $ti-1;
					print "lineages too divergent, ending at taxon $outi\n";
					last;
				}
				
				print "sufficient similarity, subsetting...";
				my @nextlinaoa;
				foreach my $i (0..$#linaoa){
					push @nextlinaoa,$linaoa[$i] if($linaoa[$i][$ti] and $matchi[$i]);
				}
				if(!@nextlinaoa){
					$outi = $ti;
					print "no further taxa for remaining lineages, ending at taxon $outi\n";
					last;
				}
				$maxlength = max( map { $#{$_} } @nextlinaoa );
				printf "%d/$totalhits lineages remain for next comparison, new maxlength of $maxlength\n", scalar @nextlinaoa;
				@linaoa = @nextlinaoa;
			}
			
			my @ind = grep { $matchi[$_] == 1 } 0..$#matchi;
			$out{$qid}{bgt} = [ @{$linaoa[$ind[0]]}[0..$outi] ];
		}
	}
	system("rm $querypath");
#	print Dumper \%out;
	return \%out;
}

sub most_frequent_indices{
	my (@items) = @_;
	my %count;
	foreach my $item (@items){
		$count{$item}++ if($item);
	}
#	print Dumper \%count;
	my $max = max(values %count);
	my @mfis = map {!defined($_) ? 0 : $count{$_} == $max ? 1 : 0 } @items;
	return @mfis;
}

sub merge_data{
	my ($hits,$taxids,$lineages) = @_;
	foreach my $qid (keys %$hits){
		foreach my $acc (keys %{${$hits}{$qid}}){
			if(exists(${$taxids}{$acc})){
				my $tid = ${$taxids}{$acc};
				${$hits}{$qid}{$acc}{tid} = $tid;
				${$hits}{$qid}{$acc}{lineage} = ${$lineages}{$tid};
			}
		}
	}
	return $hits;
}

sub parse_blastdump{
	my ($blastdump) = @_;
	my %hits;
	open my $bd, '<', \$blastdump;
	my %acchash;
	while(my $row = <$bd>){
		chomp $row;
		my @line = split /\t/, $row;
		$hits{$line[0]}{$line[1]}{score} = $line[2];
		$acchash{$line[1]} = 1;
	}
	close $bd;
	my @accessions = keys %acchash;
	return (\%hits,\@accessions);
}

sub parse_nucdump{
	my ($nucdump) = @_;
	my %tids;
	open my $nd, '<', \$nucdump;
	my @taxids;
	my ($acc,$tid);
	while(my $row = <$nd>){
		chomp $row;
#		print $row," - ";
		if($row eq "<TSeq>"){
			($acc,$tid) = (undef,undef);
#			print "start of section, reset\n";
		} elsif($row =~ /<TSeq_accver>([^.<]+)[^<]+<\/TSeq_accver>/){
			$acc = $1;
#			print "found accession $acc\n";
		} elsif($row =~ /<TSeq_taxid>(\d+)<\/TSeq_taxid>/){
			$tid = $1;
#			print "found tid $tid\n";
			push @taxids,$tid;
		} elsif($row eq "<\/TSeq>"){
			$tids{$acc} = $tid;
#			print "end of section, placed tid into hash\n"; 
#		} else {
#			print "not relevant\n";
		}
	}
	close $nd;
	my $taxidstring = join(',',@taxids);
	return (\%tids,$taxidstring);
}

sub parse_taxdump{
	my ($taxdump) = @_;
	my %lins;
	open my $td, '<', \$taxdump;
	my ($flag,$tid,$lineage, $species);
	while(my $row = <$td>){
		chomp $row;
#		print $row, " - ";
		if($row =~ /<Taxon>/){
			$flag++;
#			print "entering taxon of level $flag\n";
		} elsif($row =~ /<TaxId>(\d+)<\/TaxId>/ and $flag == 1){
			$tid = $1;
#			print "found taxid $tid\n"
		} elsif($row =~ /<Lineage>([^<]+)<\/Lineage>/ and $flag == 1){
			$lineage = $1;
#			print "found lineage $lineage\n";
		} elsif($row =~ /<ScientificName>([^<]+)<\/ScientificName>/ and $flag == 1){
			$species = $1;
#			print "found lineage $lineage\n";
		} elsif($row =~/<\/Taxon>/){
#			print "end of taxon level $flag";
			$flag--;
			if($flag == 0){
#				print "placing lineage into hash for tid and resetting\n";
				$lins{$tid} = $lineage;
				$lins{$tid} .= "; $species" if $species;
				($tid,$lineage,$species) = (undef,undef,undef);
#			} else {
#				print "not yet at low enough level to add to hash\n";
			}
#		} else {
#			print "not relevant\n";
		}
	}
	close $td;
	return \%lins;
}

sub timestamp{
my @time = localtime;
return sprintf "%02d:%02d:%02d",$time[2],$time[1],$time[0];
}

sub parse_parameters {
	my ($inmode, $inparams) = @_;
	my @itarray;
	my @paramarray;
	my $n_singleparams;
	die "Input parameters not single values, did you mean to use \"--mode eval\"?\n" unless $inmode eq "eval" or all { $_ =~ /^[^,-]*$/ } values %$inparams;
	foreach my $param (keys %$inparams){
		push @paramarray, $param;
		if($inmode eq "batch"){
			push @itarray, [$inparams->{$param}];
		} elsif ($inmode eq "eval"){
			if ($inparams->{$param} =~ /^(\d+(\.\d+)?)-(\d+(\.\d+)?),(\d+(\.\d+)?)$/ ){
				my @values;
				my $curmax = $1;
				while ($curmax <= $3){
					push @values, $curmax;
					$curmax += $5;
				}
				push @itarray, \@values;
			} elsif($inparams->{$param} =~ /^[a-zA-Z]+(?:,[a-zA-Z]+)+$/){
				my @values = split ',',$inparams->{$param};
				push @itarray, \@values;
			} elsif($inparams->{$param} =~ /^[a-zA-Z]+$|^\d+(\.\d+)?$/){
				push @itarray, [$inparams->{$param}];
				$n_singleparams++;
				die "No parameter ranges given, did you mean to use \"--mode run\"?\n" if($n_singleparams == scalar keys %$inparams);
			} else {
				die "Could not successfully parse string given for $param\n";
			}
		} else {
			die "Argument passed to --mode not recognised, see \"$script --help\" for more information\n"
		}
	}
	
	my @allarray;
	
	NestedLoops(\@itarray, sub {push @allarray, [ @_ ]});
#	print Dumper \@allarray;
	my $nonint_removed;
	my %iterhash;
	foreach my $it (0 .. $#allarray){
		$iterhash{$it+1} = {map { $paramarray[$_] => $allarray[$it][$_] } 0..$#paramarray};
		if($iterhash{$it+1}{cluster_method} eq "swarm" and $iterhash{$it+1}{otuassign} =~ /\./){
			delete($iterhash{$it+1});
			$nonint_removed++;
		}
	}
	my $newid = 1;
	my %newhash;
	foreach my $oldid (keys %iterhash){
		$newhash{$newid} = $iterhash{$oldid};
		$newid++
	}
#	print Dumper \%iterhash;
	return (\%newhash,$nonint_removed);
}

sub read_fasta {
	my ($fapathin,$checklabel) = @_;
	my %fasta;
	my $id;
	my ($name,$dir)=fileparse($fapathin);
	$name =~ s/^(.+)\.[^.]+$/$1/;
	my $barcodelabelsadded;
	open my $fa_in, '<', $fapathin or die "Couldn't open $fapathin\n";
	while(my $row = <$fa_in>){
		chomp $row;
		if($row =~ /^>(.+)$/){
			$id = $1;
			if($checklabel and !($id =~ /;barcodelabel=\w+;/)){
				$barcodelabelsadded++;
				$id.=";barcodelabel=$name;";
			}
			$id =~ s/\s/_/g;
		} elsif($row =~ /^[ATCGNatcgn]+$/){
			$fasta{$id} .= $row;
		} else { die "Couldn't read fasta format in $fapathin" };
	}
	close $fa_in;
	print "File $fapathin missing barcode labels, \";barcodelabel=$name;\" appended to header of $barcodelabelsadded sequences\n" if $checklabel and $barcodelabelsadded and $verbose;
	return %fasta;
}

sub convert_uc_and_write {
	my ($ucpath,$outpath) = @_;
	my %tab;
	my %samples;
	my %otus;
	open my $uc, '<', $ucpath or die "Error opening $ucpath\n";
	while(my $row = <$uc>){
		chomp $row;
		if($row =~ /H.*barcodelabel=(\w+);\t(.*)$/){
			$tab{$1}{$2}++;
			$samples{$1}=1;
			$otus{$2}=1;
		}
	}
	close $uc;
	open my $csv, '>', $outpath or die "Error opening $outpath\n";
	print $csv "sample,",join(",",sort keys %otus),"\n";
	foreach my $sample (sort keys %samples){
		print $csv $sample;
		foreach my $otu (sort keys %otus){
			print $csv ",",$tab{$sample}{$otu} ? $tab{$sample}{$otu} : 0;
		}
		print $csv "\n";
	}
	close $csv;
}
